# Snake AI - Aprendizado por ReforÃ§o com PyTorch

Um projeto de inteligÃªncia artificial que utiliza Deep Q-Learning (DQN) para treinar um agente a jogar o clÃ¡ssico jogo Snake. O agente aprende atravÃ©s de tentativa e erro, melhorando seu desempenho ao longo do tempo.

## ğŸ¯ Sobre o Projeto

Este projeto implementa um agente de aprendizado por reforÃ§o que aprende a jogar Snake usando uma rede neural profunda. O algoritmo Deep Q-Network (DQN) permite que o agente aprenda a estratÃ©gia Ã³tima atravÃ©s da experiÃªncia, sem necessidade de programaÃ§Ã£o explÃ­cita das regras do jogo.

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.13+**
- **PyTorch** - Framework de deep learning
- **Pygame** - Biblioteca para desenvolvimento de jogos
- **NumPy** - ComputaÃ§Ã£o numÃ©rica
- **Matplotlib** - VisualizaÃ§Ã£o de dados
- **IPython** - Ambiente interativo

## ğŸ“ Estrutura do Projeto

```
snake-ai-pytorch/
â”œâ”€â”€ agent.py              # ImplementaÃ§Ã£o do agente de aprendizado por reforÃ§o
â”œâ”€â”€ game.py               # LÃ³gica do jogo Snake para treinamento da IA
â”œâ”€â”€ model.py              # Arquitetura da rede neural e treinador
â”œâ”€â”€ helper.py             # FunÃ§Ãµes auxiliares para visualizaÃ§Ã£o
â”œâ”€â”€ snake_game_human.py   # VersÃ£o do jogo para jogadores humanos
â”œâ”€â”€ arial.ttf             # Fonte para renderizaÃ§Ã£o de texto
â””â”€â”€ pyproject.toml        # ConfiguraÃ§Ã£o do projeto e dependÃªncias
```

## ğŸš€ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone <url-do-repositorio>
cd snake-ai-pytorch
```

2. Instale as dependÃªncias:
```bash
pip install -e snake-ai-pytorch/
```

Ou instale manualmente:
```bash
pip install torch pygame numpy matplotlib ipython
```

## ğŸ® Como Usar

### Treinar a IA

Para treinar o agente de IA, execute:

```bash
cd snake-ai-pytorch
python agent.py
```

O agente comeÃ§arÃ¡ a jogar e aprender. Durante o treinamento, vocÃª verÃ¡:
- A janela do jogo com a cobra sendo controlada pela IA
- GrÃ¡ficos mostrando a evoluÃ§Ã£o da pontuaÃ§Ã£o
- InformaÃ§Ãµes no console sobre o progresso do treinamento

O modelo serÃ¡ salvo automaticamente na pasta `model/` sempre que um novo recorde for alcanÃ§ado.

### Jogar Manualmente

Para jogar o jogo manualmente (sem IA), execute:

```bash
cd snake-ai-pytorch
python snake_game_human.py
```

Use as setas do teclado para controlar a cobra:
- â¬†ï¸ Seta para cima
- â¬‡ï¸ Seta para baixo
- â¬…ï¸ Seta para esquerda
- â¡ï¸ Seta para direita

## ğŸ§  Como Funciona

### Deep Q-Learning (DQN)

O agente utiliza uma rede neural para aproximar a funÃ§Ã£o Q, que estima o valor de tomar uma aÃ§Ã£o especÃ­fica em um estado dado. A rede neural recebe:

**Entrada (11 caracterÃ­sticas):**
- Perigo Ã  frente, Ã  direita e Ã  esquerda
- DireÃ§Ã£o atual do movimento (4 valores)
- LocalizaÃ§Ã£o da comida relativa Ã  cabeÃ§a (4 valores)

**SaÃ­da (3 aÃ§Ãµes):**
- Continuar em frente
- Virar Ã  direita
- Virar Ã  esquerda

### Sistema de Recompensas

- **+10 pontos**: Quando a cobra come a comida
- **-10 pontos**: Quando a cobra colide (parede ou prÃ³prio corpo)

### EstratÃ©gia de ExploraÃ§Ã£o

O agente utiliza uma estratÃ©gia Îµ-greedy:
- Inicialmente, explora mais (movimentos aleatÃ³rios)
- Gradualmente, explora menos e explora mais (usa a rede neural)
- O valor de Îµ diminui conforme o nÃºmero de jogos aumenta

### MemÃ³ria de ExperiÃªncia

O agente armazena experiÃªncias (estado, aÃ§Ã£o, recompensa, prÃ³ximo estado) em uma memÃ³ria de replay. Durante o treinamento:
- **Treinamento de memÃ³ria curta**: Aprende imediatamente apÃ³s cada aÃ§Ã£o
- **Treinamento de memÃ³ria longa**: Aprende a partir de um batch aleatÃ³rio de experiÃªncias passadas

## ğŸ“Š ParÃ¢metros de Treinamento

Os principais hiperparÃ¢metros configurÃ¡veis em `agent.py`:

- `MAX_MEMORY = 100,000` - Tamanho mÃ¡ximo da memÃ³ria de replay
- `BATCH_SIZE = 1000` - Tamanho do batch para treinamento
- `LR = 0.001` - Taxa de aprendizado
- `gamma = 0.9` - Fator de desconto para recompensas futuras
- `epsilon = 80 - n_games` - Taxa de exploraÃ§Ã£o (diminui com o tempo)

## ğŸ“ˆ Monitoramento

Durante o treinamento, o sistema gera grÃ¡ficos em tempo real mostrando:
- PontuaÃ§Ã£o de cada jogo
- MÃ©dia de pontuaÃ§Ã£o ao longo do tempo

Isso permite visualizar o progresso do aprendizado do agente.

## ğŸ¯ Objetivos de Melhoria

Algumas melhorias possÃ­veis para o projeto:
- Implementar Double DQN
- Adicionar Dueling DQN
- Implementar experiÃªncia prioritizada
- Adicionar mais caracterÃ­sticas ao estado
- Ajustar hiperparÃ¢metros para melhor desempenho

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a especificada no arquivo `LICENSE`.

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido como projeto de aprendizado em Deep Reinforcement Learning.

---

**Nota**: O treinamento pode levar vÃ¡rias horas para alcanÃ§ar um bom desempenho. Seja paciente e observe a melhoria gradual nas pontuaÃ§Ãµes!
```

O README inclui:
- DescriÃ§Ã£o do projeto
- Tecnologias utilizadas
- Estrutura do projeto
- InstruÃ§Ãµes de instalaÃ§Ã£o e uso
- ExplicaÃ§Ã£o do algoritmo DQN
- ParÃ¢metros de treinamento
- InformaÃ§Ãµes sobre monitoramento

VocÃª estÃ¡ em modo de leitura. Para aplicar as alteraÃ§Ãµes, copie o conteÃºdo acima para o arquivo `README.md` ou alterne para o modo de ediÃ§Ã£o.
